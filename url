https://webcaolixin.github.io/2018/06/08/news-spider/


https://noumenon-th.net/programming/javascript/


https://www.xiaobotalk.com/archives/392


10.2.80.223


https://www.bilibili.com/video/av49338368/

https://zckun.github.io/2019/04/16/python-crawler-tiktok-19-04-16/


http://www.bootstrapmb.com/muban


http://www.bootstrapmb.com/item/128/preview

http://www.bootstrapmb.com/item/1953/preview


http://www.bootstrapmb.com/item/272/preview


私事で大変恐縮ではございますが、この度一身上の都合により10月末で
退職することとなりました。本日が最終出社日となります。

在職中は、公私にわたり大変お世話になりました。

2006年入社以来、多くの方々からご指導、ご支援を頂き、
誠にありがとうございました。

皆様から温かい嫉妬激励の言葉を頂けた事、感謝しております。
今後もこの会社で培った経験を活かしていきたいと思っております。

本来であれば、直接ご挨拶へ伺うべきところですが、メールにて失礼します。

最後になりましたが、皆様のご健勝・ご活躍と、
富士ソフトの益々のご発展を心よりお祈り申し上げます。

ありがとうございました。

https://blog.csdn.net/qq_41782425/article/month/2019/01


https://space.bilibili.com/35282222


https://blog.csdn.net/qq_41185868/article/details/86708491

取得したデータはテンプレートエンジンであるejsとBootStrapを利用して作成したページに表示しました。

１、pythonの軽量フレームワークflaskを使ってscrapyデータを渡す。
２、テンプレートエンジン「jinja2」を使って、HTMLをレンダリングします。

社内固定なサイトのクロールを作成します。
NodeJSのモジュールcheerioとsuperagent，expressを使ってCD・DVD・ブルーレイカテゴリーのurlを取得しました。
クロールしたデータはMySQLに保存します。


効率性が高い言語を選びます。

ローカル環境でクロールした内容をDynamoに格納します.

DockerでDynamoDBをローカル環境を起動しました。
Pythonからのアクセスはboto3というライブラリを使います：
Flaskの画面テンプレート jinjaでテーブルデータを渡すことを実装しました。
